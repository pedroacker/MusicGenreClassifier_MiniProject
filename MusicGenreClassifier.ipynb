{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Genre Classification using CNN or classic ML\n",
    "\n",
    "The idea of this mini project is to deploy a music genre classifier into a web application. Music genre classification (MGC) has been a problem in music information retrieval (MIR) for a long time - starting with the problem of what a genre actually is. For this project, however, I assume that genre boundaries are somewhat known, and use a labeled dataset (GTZAN, Free Music Archive (FMA) or Audio set) to perform classification using either CNN or classic ML techniques, depending on time constraints. \n",
    "\n",
    "For the CNN implementation, transfer learning can be done using the VGG-16 architecture with the fixed weights, or just as a starting point. The NN consists of 5 convolutional blocks, and the output layer would be ea softmax activation. I would need to download the architecture, change the output layer, use regularization and dropout to reduce overfitting (reported by the referencee) and feed the songs' spectrograms as inputs. \n",
    "\n",
    "For the ML implementation, I would have to manually extract the features. This would be done using the audio library librosa to extract frequency domain features (Mel-frequency Cepstral Coefficients (MFCC), Spectral Centroid, Spectral Roll-off...) and time domain features (Central moments, Zero Crossing Rate (ZCR), Root Means Squared Energy (RMSE)...). Those would then be fed into one or several classifiers for comparison (logistic regression, random forest, gradient boosting, support vector machines...).\n",
    "\n",
    "The evaluation consists of standard accuracy, f-score and AUC scores.\n",
    "\n",
    "Other ideas could be speech classification or noise reduction, but both of those seem considerably more complex and less flexible (solely based on DL with RNN, LSTM and CNN with millions of parameters and extensive literature background).\n",
    "\n",
    "Reference:\n",
    "Bahuleyan, Hareesh. Music Genre Classification using Machine Learning Techniques. University of Waterloo, 2018."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideal: mid-sized problems\n",
    "\n",
    "- version control\n",
    "- work with real world dataset\n",
    "- clean dataset\n",
    "- maybe extract audio features\n",
    "- optimize machine learning algorithm\n",
    "- deploy\n",
    "\n",
    "work with DL, expandable projects (CNN, like MGC)\n",
    "\n",
    "- python\n",
    "- librosa\n",
    "- tensorflow/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report, precision_recall_curve, roc_curve, roc_auc_score\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading audio files for visualization and analysis\n",
    "\n",
    "audio_file = \"../MLME_MiniProject/classical.00007.wav\"\n",
    "ipd.Audio(audio_file)\n",
    "classical, sr = librosa.load(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.head: <bound method NDFrame.head of                filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
      "0     blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
      "1     blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
      "2     blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
      "3     blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
      "4     blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
      "...                 ...     ...               ...              ...       ...   \n",
      "9985   rock.00099.5.wav   66149          0.349126         0.080515  0.050019   \n",
      "9986   rock.00099.6.wav   66149          0.372564         0.082626  0.057897   \n",
      "9987   rock.00099.7.wav   66149          0.347481         0.089019  0.052403   \n",
      "9988   rock.00099.8.wav   66149          0.387527         0.084815  0.066430   \n",
      "9989   rock.00099.9.wav   66149          0.369293         0.086759  0.050524   \n",
      "\n",
      "       rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0     0.003521             1773.065032          167541.630869   \n",
      "1     0.001450             1816.693777           90525.690866   \n",
      "2     0.004620             1788.539719          111407.437613   \n",
      "3     0.002448             1655.289045          111952.284517   \n",
      "4     0.001701             1630.656199           79667.267654   \n",
      "...        ...                     ...                    ...   \n",
      "9985  0.000097             1499.083005          164266.886443   \n",
      "9986  0.000088             1847.965128          281054.935973   \n",
      "9987  0.000701             1346.157659          662956.246325   \n",
      "9988  0.000320             2084.515327          203891.039161   \n",
      "9989  0.000067             1634.330126          411429.169769   \n",
      "\n",
      "      spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
      "0                 1972.744388           117335.771563  ...   39.687145   \n",
      "1                 2010.051501            65671.875673  ...   64.748276   \n",
      "2                 2084.565132            75124.921716  ...   67.336563   \n",
      "3                 1960.039988            82913.639269  ...   47.739452   \n",
      "4                 1948.503884            60204.020268  ...   30.336359   \n",
      "...                       ...                     ...  ...         ...   \n",
      "9985              1718.707215            85931.574523  ...   42.485981   \n",
      "9986              1906.468492            99727.037054  ...   32.415203   \n",
      "9987              1561.859087           138762.841945  ...   78.228149   \n",
      "9988              2018.366254            22860.992562  ...   28.323744   \n",
      "9989              1867.422378           119722.211518  ...   38.801735   \n",
      "\n",
      "      mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  \\\n",
      "0       -3.241280   36.488243     0.722209   38.099152    -5.050335   \n",
      "1       -6.055294   40.677654     0.159015   51.264091    -2.837699   \n",
      "2       -1.768610   28.348579     2.378768   45.717648    -1.938424   \n",
      "3       -3.841155   28.337118     1.218588   34.770935    -3.580352   \n",
      "4        0.664582   45.880913     1.689446   51.363583    -3.392489   \n",
      "...           ...         ...          ...         ...          ...   \n",
      "9985    -9.094270   38.326839    -4.246976   31.049839    -5.625813   \n",
      "9986   -12.375726   66.418587    -3.081278   54.414265   -11.960546   \n",
      "9987    -2.524483   21.778994     4.809936   25.980829     1.775686   \n",
      "9988    -5.363541   17.209942     6.462601   21.442928     2.354765   \n",
      "9989   -11.598399   58.983097    -0.178517   55.761299    -6.903252   \n",
      "\n",
      "      mfcc19_var  mfcc20_mean  mfcc20_var  label  \n",
      "0      33.618073    -0.243027   43.771767  blues  \n",
      "1      97.030830     5.784063   59.943081  blues  \n",
      "2      53.050835     2.517375   33.105122  blues  \n",
      "3      50.836224     3.630866   32.023678  blues  \n",
      "4      26.738789     0.536961   29.146694  blues  \n",
      "...          ...          ...         ...    ...  \n",
      "9985   48.804092     1.818823   38.966969   rock  \n",
      "9986   63.452255     0.428857   18.697033   rock  \n",
      "9987   48.582378    -0.299545   41.586990   rock  \n",
      "9988   24.843613     0.675824   12.787750   rock  \n",
      "9989   39.485901    -3.412534   31.727489   rock  \n",
      "\n",
      "[9990 rows x 60 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Importing the data set CSV\n",
    "\n",
    "data = pd.read_csv(\"../MusicGenreClassifier_MiniProject/Data/features_3_sec.csv\")\n",
    "print(f\"data.head: {data.head}\")#, data.info(): {data.info()}\")  # Visualizing the data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the length and filename columns\n",
    "data = data.drop(['length', 'filename'], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (9990, 57), y shape: (9990,)\n"
     ]
    }
   ],
   "source": [
    "y = data['label'] # Getting the label column\n",
    "X = data.loc[:, data.columns != 'label'] # All columns except for label as input\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "0             0.335406         0.091048  0.130405  0.003521   \n",
       "1             0.343065         0.086147  0.112699  0.001450   \n",
       "2             0.346815         0.092243  0.132003  0.004620   \n",
       "3             0.363639         0.086856  0.132565  0.002448   \n",
       "4             0.335579         0.088129  0.143289  0.001701   \n",
       "...                ...              ...       ...       ...   \n",
       "9985          0.349126         0.080515  0.050019  0.000097   \n",
       "9986          0.372564         0.082626  0.057897  0.000088   \n",
       "9987          0.347481         0.089019  0.052403  0.000701   \n",
       "9988          0.387527         0.084815  0.066430  0.000320   \n",
       "9989          0.369293         0.086759  0.050524  0.000067   \n",
       "\n",
       "      spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "0                1773.065032          167541.630869              1972.744388   \n",
       "1                1816.693777           90525.690866              2010.051501   \n",
       "2                1788.539719          111407.437613              2084.565132   \n",
       "3                1655.289045          111952.284517              1960.039988   \n",
       "4                1630.656199           79667.267654              1948.503884   \n",
       "...                      ...                    ...                      ...   \n",
       "9985             1499.083005          164266.886443              1718.707215   \n",
       "9986             1847.965128          281054.935973              1906.468492   \n",
       "9987             1346.157659          662956.246325              1561.859087   \n",
       "9988             2084.515327          203891.039161              2018.366254   \n",
       "9989             1634.330126          411429.169769              1867.422378   \n",
       "\n",
       "      spectral_bandwidth_var  rolloff_mean   rolloff_var  ...  mfcc16_mean  \\\n",
       "0              117335.771563   3714.560359  1.080790e+06  ...    -2.853603   \n",
       "1               65671.875673   3869.682242  6.722448e+05  ...     4.074709   \n",
       "2               75124.921716   3997.639160  7.907127e+05  ...     4.806280   \n",
       "3               82913.639269   3568.300218  9.216524e+05  ...    -1.359111   \n",
       "4               60204.020268   3469.992864  6.102111e+05  ...     2.092937   \n",
       "...                      ...           ...           ...  ...          ...   \n",
       "9985            85931.574523   3015.559458  8.479527e+05  ...     5.773784   \n",
       "9986            99727.037054   3746.694524  1.170890e+06  ...     2.074155   \n",
       "9987           138762.841945   2442.362154  2.602871e+06  ...    -1.005473   \n",
       "9988            22860.992562   4313.266226  4.968878e+05  ...     4.123402   \n",
       "9989           119722.211518   3462.042142  1.517016e+06  ...     1.342274   \n",
       "\n",
       "      mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  \\\n",
       "0      39.687145    -3.241280   36.488243     0.722209   38.099152   \n",
       "1      64.748276    -6.055294   40.677654     0.159015   51.264091   \n",
       "2      67.336563    -1.768610   28.348579     2.378768   45.717648   \n",
       "3      47.739452    -3.841155   28.337118     1.218588   34.770935   \n",
       "4      30.336359     0.664582   45.880913     1.689446   51.363583   \n",
       "...          ...          ...         ...          ...         ...   \n",
       "9985   42.485981    -9.094270   38.326839    -4.246976   31.049839   \n",
       "9986   32.415203   -12.375726   66.418587    -3.081278   54.414265   \n",
       "9987   78.228149    -2.524483   21.778994     4.809936   25.980829   \n",
       "9988   28.323744    -5.363541   17.209942     6.462601   21.442928   \n",
       "9989   38.801735   -11.598399   58.983097    -0.178517   55.761299   \n",
       "\n",
       "      mfcc19_mean  mfcc19_var  mfcc20_mean  mfcc20_var  \n",
       "0       -5.050335   33.618073    -0.243027   43.771767  \n",
       "1       -2.837699   97.030830     5.784063   59.943081  \n",
       "2       -1.938424   53.050835     2.517375   33.105122  \n",
       "3       -3.580352   50.836224     3.630866   32.023678  \n",
       "4       -3.392489   26.738789     0.536961   29.146694  \n",
       "...           ...         ...          ...         ...  \n",
       "9985    -5.625813   48.804092     1.818823   38.966969  \n",
       "9986   -11.960546   63.452255     0.428857   18.697033  \n",
       "9987     1.775686   48.582378    -0.299545   41.586990  \n",
       "9988     2.354765   24.843613     0.675824   12.787750  \n",
       "9989    -6.903252   39.485901    -3.412534   31.727489  \n",
       "\n",
       "[9990 rows x 57 columns]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label encoded output y_le is: [0 0 0 ... 9 9 9], original classes: ['blues' 'classical' 'country' 'disco' 'hiphop' 'jazz' 'metal' 'pop'\n",
      " 'reggae' 'rock']\n"
     ]
    }
   ],
   "source": [
    "# Using LabelEncoder to transform genres into numerical values\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "# le.classes_ # outputs the labels\n",
    "y_le = le.transform(y) # transforms the labels into numerical values\n",
    "# le.inverse_transform(y) # retrieves the original labels afterwards\n",
    "\n",
    "print(f\"The label encoded output y_le is: {y_le}, original classes: {le.classes_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/code/andradaolteanu/work-w-audio-data-visualise-classify-recommend\n",
    "\n",
    "#### NORMALIZE X ####\n",
    "\n",
    "# Normalizing increased the accuracy by almost 20%\n",
    "\n",
    "# Normalize so everything is on the same scale. \n",
    "\n",
    "cols = X.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# new data frame with the new scaled data. \n",
    "X = pd.DataFrame(np_scaled, columns = cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (6993, 57) y_train.shape: (6993,)\n",
      "X_cv.shape (1498, 57) y_cv.shape: (1498,)\n",
      "X_test.shape: (1499, 57) y_test.shape (1499,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train, cross-validation and test using sklearn\n",
    "\n",
    "X_train, X_, y_train, y_ = train_test_split(X, y_le, test_size=0.3, random_state=1)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_, y_, test_size=0.5, random_state=1)\n",
    "\n",
    "print(f\"X_train.shape:\", X_train.shape, \"y_train.shape:\", y_train.shape)\n",
    "print(f\"X_cv.shape\", X_cv.shape, \"y_cv.shape:\", y_cv.shape)\n",
    "print(\"X_test.shape:\", X_test.shape, \"y_test.shape\", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to assess different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_assess (model, title = \"Default\"):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    #predictions = model.predict(X_cv)\n",
    "    #print('Accuracy', title, ':', round(accuracy_score(y_test, predictions), 5), '\\n')\n",
    "    accuracy = model.score(X_cv, y_cv)\n",
    "    print(f\"Accuracy for {title} is {format(accuracy)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Support Vector Machine is 0.7576769025367156\n",
      "Accuracy for Logistic Regression is 0.7002670226969292\n"
     ]
    }
   ],
   "source": [
    "# Testing logistic regression\n",
    "# From Microsoft 4.2\n",
    "\n",
    "# Problems with solver multinomial (asking for scaling data or\n",
    "# increasing max_iter. The second doesn't work, the first seems\n",
    "# out of scope. Used 'ovr' (one vs rest) instead.)\n",
    "\n",
    "# similar results with linear and lbfgs solvers\n",
    "# (acc for lbfgs = 0.53)\n",
    "\n",
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=100000)\n",
    "#model = lr.fit(X_train, y_train) #np.ravel(y_train))\n",
    "\n",
    "#accuracy = model.score(X_cv, y_cv)\n",
    "#print(\"Accuracy is {}\".format(accuracy))\n",
    "\n",
    "model_assess(lr, \"Logistic Regression\")\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(decision_function_shape=\"ovo\")\n",
    "model_assess(svm, \"Support Vector Machine\")\n",
    "\n",
    "# Cross Gradient Booster - to implement or not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1488</th>\n",
       "      <th>1489</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>1492</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.764226</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.043317</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>0.083650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.108869</td>\n",
       "      <td>0.042488</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.124806</td>\n",
       "      <td>0.024727</td>\n",
       "      <td>0.070758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069429</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.018166</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.074895</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.739149</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.713253</td>\n",
       "      <td>0.010760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.045113</td>\n",
       "      <td>0.019869</td>\n",
       "      <td>0.448341</td>\n",
       "      <td>0.013455</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>0.101188</td>\n",
       "      <td>0.243108</td>\n",
       "      <td>0.051523</td>\n",
       "      <td>0.050641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428619</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.043928</td>\n",
       "      <td>0.018508</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.055118</td>\n",
       "      <td>0.278171</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.006032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048035</td>\n",
       "      <td>0.030282</td>\n",
       "      <td>0.086804</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.432675</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.359239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070628</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.587163</td>\n",
       "      <td>0.785164</td>\n",
       "      <td>0.022565</td>\n",
       "      <td>0.083361</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.077173</td>\n",
       "      <td>0.036326</td>\n",
       "      <td>0.239054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.118028</td>\n",
       "      <td>0.043396</td>\n",
       "      <td>0.023867</td>\n",
       "      <td>0.020496</td>\n",
       "      <td>0.227226</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.333696</td>\n",
       "      <td>0.094231</td>\n",
       "      <td>0.342078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.014148</td>\n",
       "      <td>0.063749</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>0.082185</td>\n",
       "      <td>0.358675</td>\n",
       "      <td>0.093537</td>\n",
       "      <td>0.009081</td>\n",
       "      <td>0.012271</td>\n",
       "      <td>0.083908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1498 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "5  0.764226  0.038262  0.013760  0.000898  0.007683  0.027945  0.000385   \n",
       "1  0.069429  0.001957  0.018166  0.000183  0.001234  0.000167  0.000046   \n",
       "3  0.050003  0.045113  0.019869  0.448341  0.013455  0.030274  0.101188   \n",
       "2  0.048035  0.030282  0.086804  0.003918  0.009612  0.432675  0.001077   \n",
       "9  0.034165  0.118028  0.043396  0.023867  0.020496  0.227226  0.001754   \n",
       "\n",
       "       7         8         9     ...      1488      1489      1490      1491  \\\n",
       "5  0.043317  0.046884  0.083650  ...  0.003461  0.108869  0.042488  0.011247   \n",
       "1  0.074895  0.000856  0.011016  ...  0.001176  0.739149  0.006904  0.009639   \n",
       "3  0.243108  0.051523  0.050641  ...  0.428619  0.006189  0.043928  0.018508   \n",
       "2  0.114442  0.020938  0.359239  ...  0.070628  0.084852  0.587163  0.785164   \n",
       "9  0.333696  0.094231  0.342078  ...  0.211242  0.014148  0.063749  0.008412   \n",
       "\n",
       "       1492      1493      1494      1495      1496      1497  \n",
       "5  0.000562  0.124271  0.004905  0.124806  0.024727  0.070758  \n",
       "1  0.000750  0.005049  0.000158  0.001985  0.713253  0.010760  \n",
       "3  0.045488  0.055118  0.278171  0.000494  0.034300  0.006032  \n",
       "2  0.022565  0.083361  0.036835  0.077173  0.036326  0.239054  \n",
       "9  0.082185  0.358675  0.093537  0.009081  0.012271  0.083908  \n",
       "\n",
       "[5 rows x 1498 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for individual accuracy, using Microsoft's function\n",
    "\n",
    "# Single row test\n",
    "cv_test = X_cv.iloc[50].values.reshape(-1, 1).T\n",
    "\n",
    "y_cv_scores = model.predict_proba(X_cv) #cv_test for the single row test\n",
    "classes = model.classes_\n",
    "resultdf = pd.DataFrame(data=y_cv_scores, columns=classes)\n",
    "\n",
    "topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])\n",
    "topPrediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1498,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv_scores[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9496903919404678\n"
     ]
    }
   ],
   "source": [
    "# Calculating Receiving Operating Characteristic (ROC)'s \n",
    "# 'Area Under the Curve' (AUC) score using the previous y_cv_scores\n",
    "\n",
    "auc = roc_auc_score(y_cv, y_cv_scores, multi_class='ovr') # y_cv_scores[:, 1]\n",
    "print(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       155\n",
      "           1       0.88      0.90      0.89       155\n",
      "           2       0.72      0.59      0.65       174\n",
      "           3       0.60      0.62      0.61       141\n",
      "           4       0.80      0.56      0.66       151\n",
      "           5       0.73      0.80      0.77       148\n",
      "           6       0.77      0.88      0.82       159\n",
      "           7       0.74      0.82      0.78       142\n",
      "           8       0.62      0.68      0.65       143\n",
      "           9       0.48      0.43      0.45       130\n",
      "\n",
      "    accuracy                           0.70      1498\n",
      "   macro avg       0.70      0.70      0.69      1498\n",
      "weighted avg       0.70      0.70      0.70      1498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report, also from scikit learn\n",
    "\n",
    "y_pred = model.predict(X_cv)\n",
    "print(classification_report(y_cv,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
